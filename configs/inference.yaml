# @package _global_

# Zero-shot inference configuration
# Usage: 
#   python -m pmf_tsfm.inference model=chronos/bolt_small data=bpi2017
#   python -m pmf_tsfm.inference model=moirai/1_1_small data=bpi2017 lora_adapter_path=./results/lora_tune/...

defaults:
  - _self_
  - paths: default
  - model: chronos/bolt_small
  - data: bpi2017

# ============== Global Settings ==============
seed: 42
print_config: false

# Task type (for output directory structure)
task: zero_shot

# Device configuration
# Options: cuda (default for cluster), mps (macOS), cpu (fallback)
# Some models may not support all devices - see device compatibility
device: cuda

# Forecasting horizon
prediction_length: 7

# LoRA adapter path (optional, for fine-tuned models)
# Set this to load a LoRA adapter for inference
lora_adapter_path: null

# Output directory structure: outputs/{task}/{dataset}/{model}/
output_dir: ${paths.output_dir}/${task}/${data.name}/${model.name}

# ============== Hydra Settings ==============
hydra:
  run:
    dir: ${paths.output_dir}/hydra/${task}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${paths.output_dir}/hydra/${task}/multirun/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  job:
    chdir: false
